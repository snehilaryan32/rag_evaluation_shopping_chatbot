{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to generate response from previous response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=st.secrets[\"OPENAI_API_KEY\"])\n",
    "\n",
    "json_file_path = \"courses.json\"\n",
    "with open(json_file_path, \"r\") as f:\n",
    "    course_data = str(json.load(f))\n",
    "\n",
    "# course_data = json_content.dumps()\n",
    "\n",
    "prompt_init = f'''Hello You are a course advisor. Accoring to the prompt use the following information\n",
    "                to reccomend courses to the student : {course_data}. Feel free to ask more questions to get more information \n",
    "                and provide better recommendations. Provide a summary of the course description, topics and \n",
    "                technologies taught and the pre requisites required to take the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you recommend a course that covers machine learning and data science?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_course_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mget_course_recommendations\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     25\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_init},\n\u001b[1;32m     27\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Send the messages to the OpenAI API and get the response\u001b[39;00m\n\u001b[1;32m     31\u001b[0m stream \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m---> 32\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[43mst\u001b[49m\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     33\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     34\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mmessages\n\u001b[1;32m     36\u001b[0m         ],\n\u001b[1;32m     37\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m response \u001b[38;5;241m=\u001b[39m stream\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI()\n",
    "\n",
    "# Load course data from a JSON file\n",
    "def load_course_data(json_file_path):\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Function to generate course recommendations\n",
    "def get_course_recommendations(prompt):\n",
    "    # Load the course data\n",
    "    course_data = load_course_data(\"courses.json\")\n",
    "    \n",
    "    # Prepare the initial system message\n",
    "    prompt_init = f'''Hello You are a course advisor. According to the prompt use the following information\n",
    "                    to recommend courses to the student: {course_data}. Feel free to ask more questions to get more information \n",
    "                    and provide better recommendations. Provide a summary of the course description, topics and \n",
    "                    technologies taught and the prerequisites required to take the course.\n",
    "                    '''\n",
    "    \n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_init},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    # Send the messages to the OpenAI API and get the response\n",
    "    stream = client.chat.completions.create(\n",
    "            model=st.session_state[\"openai_model\"],\n",
    "            messages=[\n",
    "                {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
    "                for m in st.session_state.messages\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "    response = stream\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_prompt = \"Can you recommend a course that covers machine learning and data science?\"\n",
    "    response = get_course_recommendations(user_prompt)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "# Sample retrieval function\n",
    "def retrieve_contexts(query: str) -> List[Dict[str, Any]]:\n",
    "    # Replace with actual retrieval logic\n",
    "    retrieved_contexts = [\n",
    "        {\"context\": \"sample context 1\", \"entities\": [\"entity1\", \"entity2\"]},\n",
    "        {\"context\": \"sample context 2\", \"entities\": [\"entity3\", \"entity4\"]},\n",
    "    ]\n",
    "    return retrieved_contexts\n",
    "\n",
    "# Sample generation function\n",
    "def generate_answer(contexts: List[Dict[str, Any]], query: str) -> str:\n",
    "    # Replace with actual generation logic\n",
    "    generated_answer = \"This is a generated answer based on provided contexts.\"\n",
    "    return generated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "# Sample retrieval function\n",
    "def retrieve_contexts(query: str) -> List[Dict[str, Any]]:\n",
    "    # Replace with actual retrieval logic\n",
    "    retrieved_contexts = [\n",
    "        {\"context\": \"sample context 1\", \"entities\": [\"entity1\", \"entity2\"]},\n",
    "        {\"context\": \"sample context 2\", \"entities\": [\"entity3\", \"entity4\"]},\n",
    "    ]\n",
    "    return retrieved_contexts\n",
    "\n",
    "# Sample generation function\n",
    "def generate_answer(contexts: List[Dict[str, Any]], query: str) -> str:\n",
    "    # Replace with actual generation logic\n",
    "    generated_answer = \"This is a generated answer based on provided contexts.\"\n",
    "    return generated_answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
